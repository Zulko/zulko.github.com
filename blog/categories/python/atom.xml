<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Python | __del__( self )]]></title>
  <link href="http://Zulko.github.io/blog/categories/python/atom.xml" rel="self"/>
  <link href="http://Zulko.github.io/"/>
  <updated>2014-06-09T14:19:10+02:00</updated>
  <id>http://Zulko.github.io/</id>
  <author>
    <name><![CDATA[Zulko]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Viennese Mazes: what they are, and how to make one]]></title>
    <link href="http://Zulko.github.io/blog/2014/04/27/viennese-mazes-what-they-are/"/>
    <updated>2014-04-27T23:34:00+02:00</updated>
    <id>http://Zulko.github.io/blog/2014/04/27/viennese-mazes-what-they-are</id>
    <content type="html"><![CDATA[<p><em>In this post I present an original concept of labyrinths and explain how they can be programmatically generated.</em></p>

<!-- more -->

<p>For some time now I have been designing labyrinths based on traffic lights, like this one:</p>

<p>{% img center /images/vmazes/viennese_maze.jpeg 550 %}</p>

<p>I call these <em>Viennese mazes</em> (long story) and since I couldn’t find anything similar on the Web, I assume that this is something new. Here are <a href="https://i.imgur.com/j2gWurM.jpg">some more</a> with other shapes, and <a href="https://i.imgur.com/bReTSfN.png">their solutions</a>.</p>

<p>These mazes are very difficult to design by hand, and this post is about how to ask your computer to do the work for you. We will see what a <em>good</em> Viennese maze is made of, and how to generate one using a simple evolutionary algorithm.</p>

<h2 id="viennese-mazes-are-a-special-kind-of-normal-mazes">Viennese mazes are (a special kind of) normal mazes</h2>

<p>My first intention with Viennese mazes was to make dynamic mazes, with <em>moving walls</em>. But under each Viennese maze there is actually a standard, old-school labyrinth.</p>

<p>To see this we must think in terms of <em>states</em>. A state describes where you are in the maze, and determines where you can go from there. In the maze above, state (c,1,a) means “I am in (c), I have passed 1 traffic light until then, and just before that I was in (a)”. From this state you cannot reach (d) as the light in this street has turned red, and you cannot reach (a) because you just came from here. But you can move to (b) or (g), that is, to state (b,2,c) or state (g,2,c). Note that states such as (c,1,a), (c,4,a), and (c,7,a) are actually the same state, because afer three moves all traffic lights come back to their original position. So there will always be a finite number of states in a Viennese maze.</p>

<p>If we draw a map of all (reachable) states and their connexions we obtain the following <em>states graph</em> :</p>

<p>{% img center /images/vmazes/graph.jpeg %}</p>

<p>The green node marks the starting point, while the blue node is a reunion of all states corresponding to the goal (m). The nodes on the $i$-th line from the top can be reached in $i$ moves but no less, thick lines go downwards and thin lines go upwards.</p>

<p>This graph looks like a classical labyrinth, with crossroads, dead ends, loops… at one glance it gives an idea of the complexity and interestingness of the original Viennese maze. Therefore, we will consider that a good Viennese maze is a maze whose states graph makes a good labyrinth.</p>

<h2 id="what-makes-a-good-labyrinth-">What makes a good labyrinth ?</h2>

<p>Here is an illustration of a few criteria which make a labyrinth insteresting :</p>

<p>{% img center /images/vmazes/classical_maze.jpeg 450 %}</p>

<ol>
  <li><strong>There must be a unique solution, the longer the better.</strong> In Viennese mazes It will be difficult to avoid loops like the one in <em>a</em>, where you leave the right track at some point and join it back later at exactly the same position. But there should be a unique mandatory path to the goal (in red in the drawing).</li>
  <li><strong>There must be plenty of loops and dead ends</strong>, like in <em>b</em> and <em>c</em>, and also links between false paths (like <em>d</em>), all of these preferally early on the path.</li>
  <li><strong>The maze should be difficult to solve backwards</strong>, by having false ending paths (like <em>e</em>). This criterion also tends to produce nicer-looking Viennese mazes, with a better balance of the different colors.</li>
</ol>

<p>For the computer to be able to compare mazes and identify the most interesting ones we define scores <script type="math/tex"> S_1, S_2, S_3 </script> which will quantify how well each of the criteria 1,2,3, are fullfilled by a given maze. For instance</p>

<script type="math/tex; mode=display">
S_1(maze) =
\begin{cases}
0, \,\, \mbox{if there is no solution,} \\
1, \,\, \mbox{if there are multiple solutions,} \\
L, \,\, \mbox{if there is a unique solution, of length $L$.}
\end{cases}
</script>

<p>The final score of a Viennese maze is given by the product</p>

<script type="math/tex; mode=display"> S = S_1^{c_1} \cdot S_2^{c_2} \cdot S_3^{c_3} </script>

<p>where the exponents <script type="math/tex"> c_1, c_2, c_3 </script> reflect the relative importance that we decide to attach to each criterion.</p>

<p>Evaluating this score on the states graph of a Viennese maze is easy: the existence and uniqueness of a solution can be checked using a simple-path-finding algorithm. Dead-ends are simply the nodes of the states graph with no descendents, and the loops of the maze correspond to the thin edges. The states graph itself and its different lines of nodes can be easily computed using Dijkstra’s efficient algorithm to find minimal paths between the start and the different states. The current Python implementation, relying on the Networkx package, enable to evaluate on the order of 1000 mazes per second (depending on their complexity).</p>

<h2 id="lets-grow-mazes-">Let’s grow mazes !</h2>

<p>Now that we have defined how to score a Viennese maze, we will provide the computer with an uncolored canvas, and we will ask for a <em>coloring</em> (initial color of each traffic light) of this canvas that produces the best score possible :</p>

<p>{% img center /images/vmazes/canvas.jpeg 250 %}</p>

<p>There are $3^{24}$ (almost three hundred billion) ways of coloring the 24 streets on this canvas, and considering all of them would be too long. But a great many of these colorings make interesting mazes, so we can just look semi-randomly for some of these.</p>

<p>An effective way to do so is to first colorize the canvas in a completely random way, then improve the coloring by repeating the following steps:</p>

<ol>
  <li>Create a new maze by randomly changing just a few colors of the current maze.</li>
  <li>Compute the score of this new maze.</li>
  <li>If the new maze scores lower than the current maze, dump it, otherwise it replaces the current maze. Go back to step 1.</li>
</ol>

<p>Here is a maze being optimized following this mutation/selection procedure (over 24000 mazes were generated, only the successive improvements are shown):</p>

<p>{% img center http://i.imgur.com/yc1lwgh.gif ‘hosted on imgur’ %}</p>

<p>This algorithm can be refined using annealing (in which you first evaluate many different mazes before refining the search around the best one), or any fancier search strategy such as genetic algorithms, ant colonies… What works best is still an open question.</p>

<h2 id="try-it-at-home">Try it at home</h2>

<p>If you want to try and make your own Viennese mazes (using for instance you district as a canvas), I wrote a Python package called <a href="http://zulko.github.io/vmfactory/">vmfactory</a> which implements all the steps discussed above. It can generate two variants of Viennese mazes: one where passing through the same light twice in a row is forbidden, and one where it isn’t (algorithmically, the only difference is the way the states graph is computed).</p>

<p>In the following example, we generate a squared canvas, we initialize a maze with random colors, optimize it, and generate a report (maze/graph/solution): </p>

<p>{% codeblock lang:python %}
from vmfactory import Vmaze_NHT
from vmfactory.canvas import squares_grid</p>

<p>canvas = squares_grid(4,4) # nodes will be numbered 0..15
# NHT means no half-turns (can’t pass a light twice in a row) 
maze = Vmaze_NHT(canvas, start = 0, goal = 15)
maze.colorize( maze.random_colors() )
maze.anneal(200,20) # optimize the maze
maze.make_report().savefig(‘myreport.png’)
{% endcodeblock %}</p>

<p>{% img center /images/vmazes/report.jpeg 550 %}</p>

<p>The package is based on Networkx, Numpy and Matplotlib. The code is rather short (most of it serves to draw fancy graphs !), and modular : you can easily change the rules, change the way the score is computed, change the optimization procedure, or the way the reports are drawn.</p>

<p>Thank you for reading until there, and happy mazing !</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Making GIFs from Video Files with Python]]></title>
    <link href="http://Zulko.github.io/blog/2014/01/23/making-animated-gifs-from-video-files-with-python/"/>
    <updated>2014-01-23T22:08:00+01:00</updated>
    <id>http://Zulko.github.io/blog/2014/01/23/making-animated-gifs-from-video-files-with-python</id>
    <content type="html"><![CDATA[<p><em>Sometimes producing a good animated GIF requires a few advanced tweaks, for which scripting can help. So I added a GIF export feature to MoviePy, a Python package originally written for video editing.</em></p>

<!-- more -->

<p>For this demo we will make a few GIFs out of this trailer:</p>

<p>{% youtube 2Jw-AeaU5WI %}</p>

<h2 id="converting-a-video-excerpt-into-a-gif">Converting a video excerpt into a GIF</h2>

<p>In what follows we import <a href="http://zulko.github.io/moviepy/">MoviePy</a>, we open the video file, we select the part between 1’22.65 (1 minute 22.65 seconds) and 1’23.2, reduce its size (to 30% of the original) and save it as a GIF:</p>

<p>{% codeblock lang:python %}
from moviepy.editor import *</p>

<p>VideoFileClip(“./frozen_trailer.mp4”).\
              subclip((1,22.65),(1,23.2)).\
              resize(0.3).\
              to_gif(“use_your_head.gif”)
{% endcodeblock %}</p>

<p>{% img center http://i.imgur.com/F1oOtnP.gif ‘Use Your Head - Hosted by imgur’ %}</p>

<h2 id="cropping-the-image">Cropping the image</h2>

<p>For my next GIF I will only keep the center of the screen. If you intend to use MoviePy, note that you can preview a clip with <code>clip.preview()</code>. During the preview clicking on a pixel will print its position, which is convenient for cropping with precision.</p>

<p>{% codeblock lang:python %}
kris_sven = VideoFileClip(“./frozen_trailer.mp4”).\
                   subclip((1,13.4),(1,13.9)).\
                   resize(0.5).\
                   crop(x1=145,x2=400).\ # remove left-right borders
                   to_gif(“kris_sven.gif”)
{% endcodeblock %}</p>

<p>{% img center http://i.imgur.com/CFFYEpd.gif ‘Kris and Sven - Hosted by imgur’ %}</p>

<h2 id="freezing-a-region">Freezing a region</h2>

<p>Many GIF makers like to <em>freeze</em> some parts of the GIF to reduce the file size and/or focus the attention on one part of the animation.</p>

<p>In the next GIF we freeze the left part of the clip. To do so we  take a snapshot of
the clip at t=0.2 seconds, we crop this snapshot to only keep the left half, then we make a composite clip which superimposes the cropped snapshot on the original clip:</p>

<p>{% codeblock lang:python %}
anna_olaf = VideoFileClip(“./frozen_trailer.mp4”).\
              subclip(87.9,88.1).\
              speedx(0.5).\ # Play at half speed
              resize(.4)</p>

<p>snapshot = anna_olaf.\
              crop(x2= anna_olaf.w/2).\ # remove right half
              to_ImageClip(0.2).\ # snapshot of the clip at t=0.2s
              set_duration(anna_olaf.duration)</p>

<p>CompositeVideoClip([anna_olaf, snapshot]).\
    to_gif(‘anna_olaf.gif’, fps=15)
{% endcodeblock %}</p>

<p>{% img center http://i.imgur.com/Fc9Qc5f.gif ‘Anna and Olaf - Hosted by imgur’ %}</p>

<h2 id="freezing-a-more-complicated-region">Freezing a more complicated region</h2>

<p>This time we will apply a custom mask to the snapshot to specify where it will be transparent (and let the animated part appear)
.
{% img center /images/gifs/mask.jpeg ‘That’s what a mask is for.’ %}</p>

<p>{% codeblock lang:python %}
import moviepy.video.tools.drawing as dw</p>

<p>anna_kris = VideoFileClip(“./frozen_trailer.mp4”, audio=False).\
              subclip((1,38.15),(1,38.5)).\
              resize(.5)</p>

<h1 id="coordinates-p1p2-define-the-edges-of-the-mask">coordinates p1,p2 define the edges of the mask</h1>
<p>mask = dw.color_split(anna_kris.size,
                      p1=(445, 20), p2=(345, 275),
                      grad_width=5) # blur the mask’s edges</p>

<p>snapshot = anna_kris.to_ImageClip().\
                 set_duration(anna_kris.duration).\
                 set_mask(ImageClip(mask, ismask=True))</p>

<p>CompositeVideoClip([anna_kris,snapshot]).\
    speedx(0.2).\
    to_gif(‘anna_kris.gif’, fps=15, fuzz=3) # fuzz= GIF compression</p>

<p>{% endcodeblock %}</p>

<p>{% img center http://i.imgur.com/SBHkNqt.gif ‘Anna and Olaf - Hosted by imgur’ %}</p>

<h2 id="time-symetrization">Time-symetrization</h2>

<p>Surely you have noticed that in the previous GIFs, the end did not always look like the beginning. As a consequence, you could see a disruption every time the animation was restarted. A way to avoid this is to time-symetrize the clip, i.e. to make the clip play once forwards, then once backwards. This way the <em>end</em> of the clip really <em>is</em> the beginning of the clip. This creates a GIF that can loop fluidly, without a real beginning or end.</p>

<p>{% codeblock lang:python %}
def time_symetrize(clip):
    “”” Returns the clip played forwards then backwards. In case
    you are wondering, vfx (short for Video FX) is loaded by
    »&gt; from moviepy.editor import * “””
    return concatenate([clip, clip.fx( vfx.time_mirror )])</p>

<p>VideoFileClip(“./frozen_trailer.mp4”, audio=False).\
          subclip(36.5,36.9).\
          resize(0.5).\
          crop(x1=189, x2=433).\
          fx( time_symetrize ).\
          to_gif(‘sven.gif’, fps=15, fuzz=2)
{% endcodeblock %}</p>

<p>{% img center http://i.imgur.com/fuqLsRG.gif ‘Sven - hosted on Imgur’ %}</p>

<p>Ok, this might be a bad example of time symetrization,it makes the snow flakes go upwards in the second half of the animation.</p>

<h2 id="adding-some-text">Adding some text</h2>

<p>In the next GIF there will be a text clip superimposed on the video clip.</p>

<p>{% codeblock lang:python %}</p>

<p>olaf = VideoFileClip(“./frozen_trailer.mp4”, audio=False).\
              subclip((1,21.6),(1,22.1)).\
              resize(.5).\
              speedx(0.5).\
              fx( time_symetrize )</p>

<h1 id="many-options-are-available-for-the-text-requires-imagemagick">Many options are available for the text (requires ImageMagick)</h1>
<p>text = TextClip(“In my nightmares\nI see rabbits.”,
                fontsize=30, color=’white’,
                font=’Amiri-Bold’, interline=-25).\
            set_pos((20,190)).\
            set_duration(olaf.duration)</p>

<p>CompositeVideoClip( [olaf, text] ).\
    to_gif(‘olaf.gif’, fps=10, fuzz=2)
{% endcodeblock %}</p>

<p>{% img center http://i.imgur.com/ZQzgNo6.gif ‘Olaf - Hosted by imgur’ %}</p>

<h2 id="making-the-gif-loopable">Making the gif loopable</h2>

<p>The following GIF features a lot of snow falling. Therefore it cannot be made loopable using time-symetrization (or you will snow floating upwards !). So we will make this animation loopable by having the beginning of the animation appear progressively (<em>fade in</em>) just before the end of the clip. The montage here is a little complicated, I cannot explain it better than with this picture:</p>

<p>{% img center /images/gifs/castle_loopable.jpeg ‘I hope it’s clear !’ 400 %}</p>

<p>{% codeblock lang:python %}
castle = VideoFileClip(“./frozen_trailer.mp4”, audio=False).\
              subclip(22.8,23.2).\
              speedx(0.2).\
              resize(.4)</p>

<p>d = castle.duration
castle = castle.crossfadein(d/2)</p>

<p>CompositeVideoClip([castle,
                    castle.set_start(d/2),
                    castle.set_start(d)]).\
   subclip(d/2, 3*d/2).\
   to_gif(‘castle.gif’, fps=5,fuzz=5)
{% endcodeblock %}</p>

<p>{% img center http://i.imgur.com/VnoRpdq.gif ‘Disney Castle - Hosted by Imgur’ %}</p>

<h2 id="another-example-of-a-gif-made-loopable">Another example of a GIF made loopable</h2>

<p>The next clip (from the movie <em>Charade</em>) was almost loopable: you can see Carry Grant smiling, then making a funny face, then coming back to normal. The problem is that at the end of the excerpt Cary is not exactly in the same position, and he is not smiling as he was at the beginning. To correct this, we take a snapshot of the first frame and we make it appear progressively at the end. This seems to do the trick.</p>

<p>{% codeblock lang:python %}
carry = VideoFileClip(“../videos/charade.mp4”, audio=False).\
              subclip((1,51,18.3),(1,51,20.6)).\
              crop(x1=102, y1=2, x2=297, y2=202)</p>

<p>d = carry.duration
snapshot = carry.to_ImageClip().\
                  set_duration(d/6).\
                  crossfadein(d/6).\
                  set_start(5*d/6)</p>

<p>CompositeVideoClip([carry, snapshot]).\
    to_gif(‘carry.gif’, fps=carry.fps, fuzz=3)
{% endcodeblock %}</p>

<p>{% img center  http://i.imgur.com/k1sz49h.gif ‘Carry Grant in Charade - Hosted by Imgur’ %}</p>

<h2 id="big-finish-background-removal">Big finish: background removal</h2>

<p>Let us dive further into the scripting madness: we consider this video around 2’16 (<em>edit: not the video I originally used, it was removed by the Youtube user, I add to find another link</em>):</p>

<p>{% youtube Nh11A41klL4 %}</p>

<p>And we will remove the background to make this gif (with transparent background):</p>

<p>{% img center http://i.imgur.com/Fo2BxBK.gif ‘PigsPolka - Hosted by imgur’ %}</p>

<p>The main difficulty was to find what the background of the scene is. To do so, the script gathers a few images in which the little pigs are are different positions (so that every part part of the background is visible on at least several (actually most) of the slides, then it takes the pixel-per-pixel median of these pictures, which gives the background.</p>

<p>{% codeblock lang:python %}
# Requires Scikit Images installed
import numpy as np
import skimage.morphology as skm
import skimage.filter as skf</p>

<p>from moviepy.editor import *</p>

<h3 id="load-the-clip">LOAD THE CLIP</h3>

<p>pigsPolka =  VideoFileClip(“pigs_in_a_polka.mp4”).\
                 subclip((2,16.85),(2,35)).\
                 resize(.5).\
                 crop(x1=140, y1=41, x2=454, y2=314)</p>

<h3 id="compute-the-background">COMPUTE THE BACKGROUND</h3>
<p># There is no single frame showing the background only (there
# is always a little pig in the screen) so we use the median of
# several carefully chosen frames to reconstitute the background.
# I must have spent half an hour to find the right set of frames.</p>

<p>times = (list(np.linspace(2.3,4.2,30))+
         list(np.linspace(6.0,7.1,30))+
         8*[6.2])</p>

<p>frames_bg = [pigsPolka.get_frame(t) for t in times]
background = np.percentile(np.array(frames_bg), 50,axis=0)</p>

<h3 id="mask-generation">MASK GENERATION</h3>

<p>def get_mask_frame(t):
    “”” Computes the mask for the frame at time t “””</p>

<pre><code># THRESHOLD THE PIXEL-TO-PIXEL DIFFERENCE
# BETWEEN THE FRAME AND THE BACKGROUND
im = pigsPolka.get_frame(t)
mask = ((im-background)**2).sum(axis=2) &gt; 1500

# REMOVE SMALL OBJECTS
mask = skm.remove_small_objects(mask)

# REMOVE SMALL HOLES (BY DILATIATION/EROSION)
selem=np.array([[1,1,1],[1,1,1],[1,1,1]])
for i in range(2):
    mask = skm.binary_dilation(mask,selem)
for i in range(2):
    mask = skm.binary_erosion(mask,selem)

# BLUR THE MASK A LITTLE
mask = skf.gaussian_filter(mask.astype(float),1.5)

return mask
</code></pre>

<p>mask = VideoClip(ismask=True).\
          set_get_frame(get_mask_frame).\
          set_duration(pigsPolka.duration)</p>

<h3 id="last-effects-and-gif-generation">LAST EFFECTS AND GIF GENERATION</h3>

<p>pigsPolka.set_mask(mask).\
          subclip(12.95,15.9).\
          fx(vfx.blackwhite).\ # black &amp; white effect !
          to_gif(‘pigs_polka.gif’, fps=10,
          dispose=True, fuzz=10)
{% endcodeblock %}</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interception of a linear trajectory with constant speed]]></title>
    <link href="http://Zulko.github.io/blog/2013/11/11/interception-of-a-linear-trajectory-with-constant-speed/"/>
    <updated>2013-11-11T23:59:00+01:00</updated>
    <id>http://Zulko.github.io/blog/2013/11/11/interception-of-a-linear-trajectory-with-constant-speed</id>
    <content type="html"><![CDATA[<p><em>In this post I show how helpful trigonometry can be when it comes to catching rabbits.</em></p>

<!-- more -->

<h2 id="problem">Problem</h2>

<p>Alice just spotted a white rabbit urging to its rabbit hole ! Given the coordinates of the positions A, B, H, of Alice, the rabbit and the hole, as well as the respective speeds $S_A$ and $S_B$ of Alice and the rabbit, say whether Alice can catch the rabbit before it disappears, and give the time and place of the fastest possible interception.</p>

<h2 id="solution">Solution</h2>

<p>I guess that I am not the first one to solve this but I couldn’t find any simple solution on the internet. The one I am giving here relies on trigonometry, but interestingly it doesn’t require to compute any trigonometrical function !</p>

<p>If sines give you fever, don’t wait for the first <em>sines of fever</em> (uh uh uh), just skip this part, I summarize everything in the next section.</p>

<p>We call  C and $t_C$ the location and the time of the catch. It is straightforward that, since we are looking for the fastest catch, Alice’s trajectory towards C must be a straight line. Here is a sketch of the problem:</p>

<p>{% img center /images/alice/alice_schema.jpeg %}
Note that the lengths AC and BC denote the distance run by Alice and the Rabbit until the catch, therefore they verify</p>

<script type="math/tex; mode=display"> AC = S_A t_C </script>

<script type="math/tex; mode=display"> BC = S_B t_C </script>

<p><strong>So finding the length BC would answer the problem</strong>, as it would tell us whether Alice can catch the rabbit before it reaches the rabbit hole (case $BC&lt;BH$), and would immediately lead to both the location and time of the catch :</p>

<script type="math/tex; mode=display"> C = B + \dfrac{BC}{BH}\overrightarrow{BH} </script>

<script type="math/tex; mode=display"> t_C = BC/S_B </script>

<p>To express BC using the coordinates of the points, let us apply the famous <em>Law of Sines</em> to the triangle ABC:</p>

<script type="math/tex; mode=display"> \dfrac{\sin \alpha}{BC} = \dfrac{\sin \beta}{AC} = \dfrac{\sin \gamma}{AB} </script>

<p>Wich leads to</p>

<script type="math/tex; mode=display"> BC = \dfrac {\sin \alpha}{\sin \gamma} AB = \dfrac {\sin \alpha}{\sin \gamma} \sqrt{(x_B-x_A)^2+(y_B-y_A)^2} </script>

<p>Now all we have to do is to express $\sin \alpha$ and $\sin \gamma$ in function of the given data. To do so we first compute $\sin(\beta)$, then we express $\sin \alpha$ with $\sin \beta$, and we express $\sin \gamma$ as a function of $\sin \alpha$ and $\sin \beta$.</p>

<p>The value of $\sin \beta$ can be computed from the points coordinates as follows:</p>

<script type="math/tex; mode=display"> \sin \beta = \dfrac{det(\overrightarrow{BA},\overrightarrow{BH})}{ BA * BH } = \dfrac{(x_A - x_B)(y_H-y_B) - (y_A - y_B)(x_H-x_B)}{\sqrt{(x_B-x_A)^2+(y_B-y_A)^2} \sqrt{(x_B-x_H)^2+(y_B-y_H)^2}} </script>

<p>Then we use the Law of Sines again, to compute $\sin \alpha$:</p>

<script type="math/tex; mode=display"> \sin \alpha = \frac{BC}{AC} \sin \beta = \frac{S_b t_C}{S_a t_C} \sin \beta = \frac{S_b}{S_a} \sin \beta </script>

<p>This only makes sense, of course, if</p>

<script type="math/tex; mode=display"> \frac{S_A}{S_R} \mid \sin \beta \mid \leq 1 </script>

<p><strong>If this is not the case we conclude that Alice will never catch the rabbit, which solves the problem.</strong></p>

<p>Finally we use the fact that the angles of a triangle sum to $\pi$ to compute $\sin \gamma$:</p>

<script type="math/tex; mode=display"> \sin \gamma = \sin (\pi - \alpha - \beta) = \sin (\alpha + \beta) = \sin \alpha \cos \beta + \cos \alpha \sin \beta </script>

<p>We reformulate using the already-copmputed $\sin \alpha$ and $\sin \beta$:</p>

<script type="math/tex; mode=display"> \sin \gamma = (\sin \alpha) \sqrt{1 - \sin^2 \beta} + (\sin \beta) \sqrt{1 - \sin^2 \alpha} </script>

<p>And… we are done, we have everything we need to compute BC and answer the problem.</p>

<h2 id="summary-and-code">Summary and code</h2>

<p>So here is the short answer to the problem:</p>

<ul>
  <li>Compute $\sin \beta$ using the formula given above.</li>
  <li>Compute $\sin \alpha = (S_b * \sin \beta)/S_a$. If $\mid \sin \alpha \mid&gt;1$, Alice cannot catch the rabbit. Otherwise, advance to step 3.</li>
  <li>Compute $\sin \gamma$ with the formula above and the values of $\sin \alpha$ and $\sin \beta$ found in steps <em>1</em> and <em>2</em>.</li>
  <li>Compute BC using the formula given above and the values found for $\sin \alpha$ and $\sin \gamma$.  If $BC&gt;BH$, the rabbit will reach its hole before Alice can catch it. Otherwise, congratulation young girl, you will eat rabbit for dinner, here are the location and time of the fastest possible interception:</li>
</ul>

<script type="math/tex; mode=display"> C = B + \frac{BC}{BH}\overrightarrow{BH} </script>

<script type="math/tex; mode=display"> t_C = BC/S_B </script>

<p>Below is a script implementing this technique using Python’s pylab module:</p>

<p>{% codeblock lang:python %}</p>

<p>from pylab import * # imports srqt, norm, array, plot…</p>

<p>def interception(A, B, H, Sa, Sb):
    “”” Returns <code>(t_C, C)</code> if A can catch B, before B 
    reaches H. Otherwise, returns <code>None</code>. “””</p>

<pre><code>sin_b = det(array((A-B,H-B))) / ( norm(A-B) * norm(H-B) )

sin_a = (Sb / Sa) * sin_b

if abs(sin_a) &gt; 1 :
    
    print "B moves too fast to be ever caught !"
    return None

else:
    
    sin_c = ( sin_a * sqrt(1 - sin_b**2)
              + sin_b * sqrt(1 - sin_a**2) )
    
    BC = norm(B-A) * (sin_a / sin_c) 
    
    if BC &gt; norm(H-A):
        
        print "B reaches H before interception by A !"
        return None
        
    else:
        
        print "A intercepted B !"
        t_C = BC / Sb
        C = B + BC * (H-B)/norm(H-B)
        return t_C,C
</code></pre>

<p>{% endcodeblock %}</p>

<p>And here it is in action:</p>

<p>{% codeblock lang:python %}</p>

<h1 id="parameters-of-the-problem">PARAMETERS OF THE PROBLEM</h1>
<p>A = array(( 1.0 , 5.0 )) # Alice’s initial position
B = array(( 4.0 , 1.0 )) # Rabbit’s initial position
H =  array(( 6.0 , 7.0 )) # Hole’s coordinates
Sa = 1.1 # Alice’s speed
Sb = 1.0 # Rabbit’s speed</p>

<h1 id="find-the-intersection">Find the intersection</h1>
<p>t,C = interception(A, B, H, Sa, Sb)</p>

<h1 id="plot-the-results">Plot the results</h1>

<p>scatter(*zip(A,B,H,C), s=100, color=’r’)</p>

<p>for label, point in zip([‘A’,’B’,’H’,’C’], [A,B,H,C]):
    annotate( label, xy = point, xytext = (-10, 10),
        textcoords = ‘offset points’, fontsize = 24)</p>

<p>annotate(“”, xy=H, xytext=B, xycoords=’data’,
         textcoords=’data’,size=20,
         arrowprops=dict(arrowstyle=”simple”,
                         connectionstyle=”arc3”))</p>

<p>annotate(“”, xy=C, xytext=A, xycoords=’data’,
         textcoords=’data’,size=20,
         arrowprops=dict(arrowstyle=”simple”,
                         connectionstyle=”arc3”))</p>

<p>title(“A intercepts B in C”, fontsize = 24)</p>

<p>show()
{% endcodeblock %}</p>

<p>{% img center /images/alice/alice_matplotlib.jpeg %}</p>
]]></content>
  </entry>
  
</feed>
