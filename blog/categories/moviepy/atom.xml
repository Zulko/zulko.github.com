<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: MoviePy, | __del__( self )]]></title>
  <link href="http://Zulko.github.io/blog/categories/moviepy/atom.xml" rel="self"/>
  <link href="http://Zulko.github.io/"/>
  <updated>2014-06-09T14:19:10+02:00</updated>
  <id>http://Zulko.github.io/</id>
  <author>
    <name><![CDATA[Zulko]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Read and write video frames in Python using FFMPEG]]></title>
    <link href="http://Zulko.github.io/blog/2013/09/27/read-and-write-video-frames-in-python-using-ffmpeg/"/>
    <updated>2013-09-27T23:53:00+02:00</updated>
    <id>http://Zulko.github.io/blog/2013/09/27/read-and-write-video-frames-in-python-using-ffmpeg</id>
    <content type="html"><![CDATA[<p><em>This article shows how easy it is to read or write video frames with Python, by calling the external software FFMPEG through pipes. Check also <a href="/blog/2013/10/04/read-and-write-audio-files-in-python-using-ffmpeg">that other article</a> for the same with audio files.</em></p>

<!-- more -->

<p>Before we start, you must have FFMPEG installed on your computer and you must know the name (or path) of the FFMPEG binary on your computer. It should be one of the following:
{% codeblock lang:python %}
FFMPEG_BIN = “ffmpeg” # on Linux
FFMPEG_BIN = “ffmpeg.exe” # on Windows
{% endcodeblock %}</p>

<h2 id="reading">Reading</h2>

<p>To read the frames of the video “myHolidays.mp4” we first ask FFMPEG to open this file and to direct its output to Python:</p>

<p>{% codeblock lang:python %}
import subprocess as sp
command = [ FFMPEG_BIN,
            ‘-i’, ‘myHolidays.mp4’,
            ‘-f’, ‘image2pipe’,
            ‘-pix_fmt’, ‘rgb24’,
            ‘-vcodec’, ‘rawvideo’, ‘-‘]
pipe = sp.Popen(command, stdout = sp.PIPE, bufsize=10**8)
{% endcodeblock %}</p>

<p>In the code above <code>-i myHolidays.mp4</code> indicates the input file, while <code>rawvideo/rgb24</code> asks for a raw RGB output. The format <code>image2pipe</code> and the <code>-</code> at the end tell FFMPEG that it is being used with a pipe by another program. In <code>sp.Popen</code>, the <code>bufsize</code> parameter must be bigger than the size of one frame (see below). It can be omitted most of the time in Python 2 but not in Python 3 where its default value is pretty small.</p>

<p>Now we just have to read the output of FFMPEG. If the video has a size of 420x320 pixels, then the first 420x360x3 bytes outputed by 
FFMPEG will give the RGB values of the pixels of the first frame, line by line, top to bottom. The next 420x360x3 bytes afer that will represent the second frame, etc.
In the next lines we extract one frame and reshape it as a 420x360x3 Numpy array:</p>

<p>{% codeblock lang:python %}
import numpy
# read 420<em>360</em>3 bytes (= 1 frame)
raw_image = pipe.stdout.read(420<em>360</em>3)
# transform the byte read into a numpy array
image =  numpy.fromstring(raw_image, dtype=’uint8’)
image = image.reshape((360,420,3))
# throw away the data in the pipe’s buffer.
pipe.stdout.flush()
{% endcodeblock %}</p>

<p>You can now view the image with for instance Pylab’s <code>imshow( image )</code>. By repeating the two lines above you can read all the frames of the video one after the other. Reading one frame with this method takes 2 milliseconds on my computer.</p>

<p>What if you want to read the frame that is at time 01h00 in the video ? You could do as above: open the pipe, and read all the frames of the video one by one until you reach that corresponding to t=01h00. But this may be VERY long. A better solution is to call FFMPEG with arguments telling it to start reading “myHolidays.mp4” at time 01h00:</p>

<p>{% codeblock lang:python %}
command = [FFMPEG_BIN,
            ‘-ss’, ‘00:59;59’,
            ‘-i’, ‘myHolidays.mp4’,
            ‘-ss’, ‘1’,
            ‘-f’, ‘image2pipe’,
            ‘-pix_fmt’, ‘rgb24’,
            ‘-vcodec’,’rawvideo’, ‘-‘]
pipe = sp.Popen(command, stdout=sp.PIPE, bufsize=10**8)
{% endcodeblock %}</p>

<p>In the code above we ask FFMPEG to quickly (and imprecisely) reach 00:59:59, then to skip 1 second of movie with precision (<code>-ss 1</code>), so that it will effectively start at 01:00:00 sharp (see <a href="https://trac.ffmpeg.org/wiki/Seeking%20with%20FFmpeg">this page</a> for more infos).Then you can start reading frames as previously shown. Seeking a frame with this method takes at most 0.1 second on my computer.</p>

<p>You can also get informations on a file (frames size, number of frames per second, etc.) by calling</p>

<p>{% codeblock lang:python %}
command = [FFMPEG_BINARY,’-i’, ‘my_video.mp4’, ‘-‘]
pipe = sp.Popen(command, stdout=sp.PIPE stderr=sp.PIPE)
pipe.stdout.readline()
pipe.terminate()
infos = proc.stderr.read()
{% endcodeblock %}</p>

<p>Now <code>infos</code> contains a text describing the file, that you would need to parse to obtain the relevant informations. See the last section for a link to an implementation.</p>

<h2 id="writing">Writing</h2>

<p>To write a series of frames of size 460x360 into the file <code>'my_output_videofile.mp4'</code>, we open FFMPEG and indicate that raw RGB data is going to be piped in:</p>

<p>{% codeblock lang:python %}
command = [ FFMPEG_BIN,
        ‘-y’, # (optional) overwrite output file if it exists
        ‘-f’, ‘rawvideo’,
        ‘-vcodec’,’rawvideo’,
        ‘-s’, ‘420x360’, # size of one frame
        ‘-pix_fmt’, ‘rgb24’,
        ‘-r’, ‘24’, # frames per second
        ‘-i’, ‘-‘, # The imput comes from a pipe
        ‘-an’, # Tells FFMPEG not to expect any audio
        ‘-vcodec’, ‘mpeg’”,
        ‘my_output_videofile.mp4’ ]</p>

<p>pipe = sp.Popen( command, stdin=sp.PIPE, stderr=sp.PIPE)
{% endcodeblock %}</p>

<p>The codec of the output video can be any valid FFMPEG codec but for many codecs you will need to provide the bitrate as an additional argument (for instance <code>-bitrate 3000k</code>). Now we can write raw frames one after another in the file. These will be raw frames, like the ones outputed by FFMPEG in the previous section: they should be strings of the form “RGBRGBRGB…” where R,G,B are <em>caracters</em> that represent a number between 0 and 255. If our frame is represented as a Numpy array, we simply write:</p>

<p>{% codeblock lang:python %}
pipe.proc.stdin.write( image_array.tostring() )
{% endcodeblock %}</p>

<h2 id="going-further">Going further</h2>

<p>I tried to keep the code as simple as possible here. With a few more lines you can make useful classes to manipulate video files, like <a href="https://github.com/Zulko/moviepy/blob/master/moviepy/video/io/ffmpeg_reader.py">FFMPEG_VideoReader</a> and <a href="https://github.com/Zulko/moviepy/blob/master/moviepy/video/io/ffmpeg_writer.py">FFMPEG_VideoWriter</a> that I wrote for my video editing software. In these files in particular how to parse the information on the video, how to save/load pictures using FFMPEG, etc.</p>
]]></content>
  </entry>
  
</feed>
